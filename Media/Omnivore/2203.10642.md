---
id: bb583b9a-929d-11ee-9e3f-9b55ed27629d
---

___
# 2203.10642

**Links**: [Omnivore](https://omnivore.app/me/2203-10642-18c34baba29) |  [Web](https://arxiv.org/pdf/2203.10642.pdf)
Status: #FILE
**Tags**: 

> [!Abstract] 
> 

**Authors**: [[]]
**Revision Date**: 
**Import Date**: 2023-12-04 13:11:11
___

# Highlights

> camera images image features LiDAR point clouds voxel features radar point features predicted 3D bounding boxes Transformer decoder Camera  Backbone LiDAR Backbone Radar Backbone + positional  encoding radar points 3D reference point sampled features Modality-Agnostic Feature Sampler (MAFS) feature  sampling Figure 2. Overview of FUTR3D. Each sensor modality is encoded individually in its own coordinate. Then a query-based Modality- Agnostic Feature Sampler (MAFS) extracts features from all available modalities according to the 3D reference point of each query. Finally a transformer decoder predicts 3D bounding boxes from queries. The predicted boxes can be iteratively fed back into MAFS and transformer decoder to refine the predictions [⤴️](https://omnivore.app/me/2203-10642-18c34baba29#6670cec9-4894-46d8-bc0a-40c864233159)  ^6670cec9

